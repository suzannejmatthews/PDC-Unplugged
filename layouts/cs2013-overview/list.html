{{ partial "header" . }}



<main align="left">

<h1>CS2013 View</h1>
<p >This view classifies PDC unplugged activities by their associated Knowledge Units (KU) and Learning Outcomes (LO) as specified by 
   	the <a href="https://www.acm.org/binaries/content/assets/education/cs2013_web_final.pdf" target=_blank>ACM/IEEE Computer Science Curricula 2013</a> (CS2013)
    Parallel and Distributed (PD) knowledge area. CS2013 recommends coverage of all LOs in Core Tier 1, and at least 80% of coverage of LOs in Core Tier 2, and a "significant" 
    level of cover of elective LOs. The following table from CS2013 gives an outline of topic coverage over the different KUs:</p>

<table border="1">
<tr><th width="40%"></th><th>Core-Tier1 hours</th> <th>Core-Tier2 hours </th> <th>Electives?</th></tr>
<tr><td>PD/Parallelism Fundamentals</td> <td>2</td><td></td><td>N</td></tr>
<tr><td>PD/Parallel Decomposition</td><td>1</td><td>3</td><td>N</td></tr>
<tr><td>PD/Communication and Coordination</td><td>1</td><td>3</td><td>Y</td></tr>
<tr><td>PD/Parallel Algorithms, Analysis, and Programming</td><td></td><td>3</td><td>Y</td></tr>
<tr><td>PD/Parallel Architecture</td><td>1</td><td>1</td><td>Y</td></tr>
<tr><td>PD/Parallel Performance</td><td></td><td></td><td>Y</td></tr>
<tr><td>PD/Distributed Systems</td><td></td><td></td><td>Y</td></tr>
<tr><td>PD/Cloud Computing</td><td></td><td></td><td>Y</td></tr>
<tr><td>PD/Formal Models and Semantics</td><td></td><td></td><td>Y</td></tr>
</table>

<p><br></p>



<h3 >Parallelism Fundamentals (<a href="{{ .Site.BaseURL }}/cs2013/pd_parallelfundamentals">{{ len .Site.Taxonomies.cs2013.pd_parallelfundamentals }} Activities  </a>)</h3>
<table>
<tr>    <th width="60%">Learning Outcome</th>   <th>Unplugged Activities</th>    </tr>
  <tr><td>1. Distinguish using computational resources for a faster answer from managing efficient access to a shared resource. [Familiarity]</td> <td>
 {{ range first 2 .Site.Taxonomies.cs2013details.fun_1 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>;
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/fun_1">See All ({{ len .Site.Taxonomies.cs2013details.fun_1 }}) </a>
</td></tr>
  <tr><td>2. Distinguish multiple sufficient programming constructs for synchronization that may be inter-implementable but have complementary advantages. [Familiarity]</td> <td></td></tr>
  <tr><td>3. Distinguish data races from higher level races.  [Familiarity]</td><td></td></tr>
</table>

<p><br></p>
  <!--<a href="{{ .Site.BaseURL }}/cs2013details/pd_2">{{ len .Site.Taxonomies.cs2013details.pd_2 }} Activities </a> -->
<h3>Parallel Decomposition (<a href="{{ .Site.BaseURL }}/cs2013/pd_paralleldecomposition">{{ len .Site.Taxonomies.cs2013.pd_paralleldecomposition }} Activities  </a>) </h3>
<table >
    <tr>
    <th  width="60%">Learning Outcome</th> 
    <th>Unplugged Activities</th>
    <tr><th>Core Tier 1 </th></tr>
<tr><td> 1. Explain why synchronization is necessary in a specific parallel program. [Usage] </td><td>   {{ range first 2 .Site.Taxonomies.cs2013details.pd_1 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/pd_1">See All ({{ len .Site.Taxonomies.cs2013details.pd_1 }}) </a>
  </td></tr>
<tr><td> 2. Identify opportunities to partition a serial program into independent parallel modules. [Familiarity]</td>
<td>
    {{ range first 2 .Site.Taxonomies.cs2013details.pd_2 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/pd_2">See All ({{ len .Site.Taxonomies.cs2013details.pd_2 }}) </a>
</td>

</tr> 
<tr><th>Core Tier 2 </th></tr>
<tr><td> 3. Write a correct and scalable parallel algorithm. [Usage]</td>
  <td>

  </td>
</tr> 

<tr><td> 4. Parallelize an algorithm by applying task-based decomposition. [Usage]</td><td>
    {{ range first 2 .Site.Taxonomies.cs2013details.pd_4 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/pd_4">See All ({{ len .Site.Taxonomies.cs2013details.pd_4 }}) </a>
  </td></tr>

<tr><td> 5. Parallelize an algorithm by applying data-parallel decomposition. [Usage]</td><td>
{{ range first 2 .Site.Taxonomies.cs2013details.pd_5 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/pd_5">See All ({{ len .Site.Taxonomies.cs2013details.pd_5 }}) </a>
</td></tr>
<tr><td> 6. Write a program using actors and/or reactive processes. [Usage]</td><td></td></tr>
</table> 

<p><br></p>

<h3>Communication and Coordination (<a href="{{ .Site.BaseURL }}/cs2013/pd_communicationandcoordination">{{ len .Site.Taxonomies.cs2013.pd_communicationandcoordination }} Activities  </a>) </h3>
<table>
    <tr>
    <th width="60%">Learning Outcome</th> <th>Unplugged Activities</th>
<tr><th>Core Tier 1 </th></tr>
<tr><td> 1. Use mutual exclusion to avoid a given race condition. [Usage] </td>
  <td>
    {{ range first 2 .Site.Taxonomies.cs2013details.cac_1 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/cac_1">See All ({{ len .Site.Taxonomies.cs2013details.cac_1 }}) </a>
  </td></tr>
<tr><td> 2. Give an example of an ordering of accesses among concurrent activities (e.g., program with a data race) that is not sequentially consistent. [Familiarity] </td>
  <td>  {{ range first 2 .Site.Taxonomies.cs2013details.cac_2 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/cac_2">See All ({{ len .Site.Taxonomies.cs2013details.cac_2 }}) </a></td></tr>
<tr><th>Core Tier 2 </th></tr>
<tr><td> 3. Give an example of a scenario in which blocking message sends can deadlock. [Usage]</td>
  <td>
      {{ range first 2 .Site.Taxonomies.cs2013details.cac_3 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/cac_3">See All ({{ len .Site.Taxonomies.cs2013details.cac_3 }}) </a></td></tr>
<tr><td> 4. Explain when and why multicast or event-based messaging can be preferable to alternatives. [Familiarity] </td>
  <td>
  
  </td></tr>
<tr><td> 5. Write a program that correctly terminates when all of a set of concurrent tasks have completed. [Usage] </td><td>
      {{ range first 2 .Site.Taxonomies.cs2013details.cac_5 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/cac_5">See All ({{ len .Site.Taxonomies.cs2013details.cac_5 }}) </a>
</td></tr>
<tr><td> 6. Use a properly synchronized queue to buffer data passed among activities. [Usage] </td><td>
  
</td></tr>
<tr><td> 7. Explain why checks for preconditions, and actions based on these checks, must share the same unit of atomicity to be effective. [Familiarity] </td>
  <td>    {{ range first 2 .Site.Taxonomies.cs2013details.cac_7 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/cac_7">See All ({{ len .Site.Taxonomies.cs2013details.cac_7 }}) </a></td></tr>
<tr><td> 8. Write a test program that can reveal a concurrent programming error; for example, missing an update when two activities both try to increment a variable. [Usage] </td>
  <td>    {{ range first 2 .Site.Taxonomies.cs2013details.cac_8 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/cac_8">See All ({{ len .Site.Taxonomies.cs2013details.cac_8 }}) </a></td></tr>
<tr><td> 9. Describe at least one design technique for avoiding liveness failures in programs using multiple locks or semaphores. [Familiarity] </td>

<tr><td> 10. Describe the relative merits of optimistic versus conservative concurrency control under different rates of contention among updates. [Familiarity] </td>
  <td>
  <td>    
  </td></tr>
<tr><td> 11. Give an example of a scenario in which an attempted optimistic update may never complete. [Familiarity] </td><td>

 </td></tr>
</td></tr>
</table>

<p><br></p>
<h3>Parallel Algorithms, Analysis, &amp; Programming ( <a href="{{ .Site.BaseURL }}/cs2013/pd_parallelalgorithms">{{ len .Site.Taxonomies.cs2013.pd_parallelalgorithms }} Activities  </a>) </h3>
<table>
    <tr>
    <th width = "60%">Learning Outcome</th> 
    <th>Unplugged Activities</th>
    <tr><th>Core Tier 2 </th></tr>
<tr><td> 1. Define "critical path", "work", and "span". [Familiarity] </td><td></td></tr>
<tr><td> 2. Compute the work and span, and determine the critical path with respect to a parallel execution diagram. [Usage] </td><td></td></tr>
<tr><td> 3. Define "speed-up" and explain the notion of an algorithm's scalability in this regard. [Familiarity] </td>
  <td>
      {{ range first 2 .Site.Taxonomies.cs2013details.algo_3 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/algo_3">See All ({{ len .Site.Taxonomies.cs2013details.algo_3 }}) </a>
  </td>
</tr>
<tr><td> 4. Identify independent tasks in a program that may be parallelized. [Usage] </td>
  <td>
       {{ range first 2 .Site.Taxonomies.cs2013details.algo_4 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/algo_4">See All ({{ len .Site.Taxonomies.cs2013details.algo_4 }}) </a>
  </td></tr>
<tr><td> 5. Characterize features of a workload that allow or prevent it from being naturally parallelized. [Familiarity]</td><td>
 {{ range first 2 .Site.Taxonomies.cs2013details.algo_5 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>;
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/algo_5">See All ({{ len .Site.Taxonomies.cs2013details.algo_5 }}) </a>

</td></tr>
<tr><td> 6. Implement a parallel divide-and-conquer (and/or graph algorithm) and empirically measure its performance relative to its sequential analog. </td>
<td>
 {{ range first 2 .Site.Taxonomies.cs2013details.algo_6 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>;
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/algo_6">See All ({{ len .Site.Taxonomies.cs2013details.algo_6 }}) </a>
</td></tr>
<tr><td> 7. Decompose a problem (e.g., counting the number of occurrences of some word in a document) via map and reduce operations.</td><td></td></tr>
<tr><th>Elective </th></tr>
<tr><td> 8. Provide an example of a problem that fits the producer-consumer paradigm. [Familiarity]</td><td></td></tr>
<tr><td> 9. Give examples of problems where pipelining would be an effective means of parallelization. [Familiarity]</td>
<td>
        {{ range first 2 .Site.Taxonomies.cs2013details.algo_9 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/algo_9">See All ({{ len .Site.Taxonomies.cs2013details.algo_9 }}) </a>
</td></tr>


<tr><td> 10. Implement a parallel matrix algorithm. [Usage]</td>
  <td>
        {{ range first 2 .Site.Taxonomies.cs2013details.algo_10 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/algo_10">See All ({{ len .Site.Taxonomies.cs2013details.algo_10 }}) </a>
  </td></tr>
<tr><td> 11. Identify issues that arise in producer-consumer algorithms and mechanisms that may be used for addressing them. [Familiarity]</td><td></td></tr>
</table>

<p><br></p>

<h3>Parallel Architecture (<a href="{{ .Site.BaseURL }}/cs2013/pd_parallelarchitecture">{{ len .Site.Taxonomies.cs2013.pd_parallelarchitecture }} Activities  </a>) </h3>

<table>
    <tr>
    <th width="60%">Learning Outcome</th> 
    <th>Unplugged Activities</th>
    <tr><th>Core Tier 1 </th></tr>
<tr><td> 1. Explain the differences between shared and distributed memory. [Familiarity] [Core-Tier2] </td><td>
   {{ range first 2 .Site.Taxonomies.cs2013details.arch_1 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/arch_1">See All ({{ len .Site.Taxonomies.cs2013details.arch_1 }}) </a>
</td></tr>
 <tr><th>Core Tier 2 </th></tr>
<tr><td> 2. Describe the SMP architecture and note its key features. [Familiarity] </td>
  <td>
       {{ range first 2 .Site.Taxonomies.cs2013details.arch_2 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/arch_2">See All ({{ len .Site.Taxonomies.cs2013details.arch_2 }}) </a>
  </td></tr>
<tr><td> 3. Characterize the kinds of tasks that are a natural match for SIMD machines. [Familiarity]</td>
  <td>   {{ range first 2 .Site.Taxonomies.cs2013details.arch_3 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/arch_3">See All ({{ len .Site.Taxonomies.cs2013details.arch_3 }}) </a></td></tr>
 <tr><th>Elective </th></tr>
<tr><td>4. Describe the advantages and limitations of GPUs vs. CPUs. [Familiarity]</td>
  <td>   {{ range first 2 .Site.Taxonomies.cs2013details.arch_4 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/arch_4">See All ({{ len .Site.Taxonomies.cs2013details.arch_4 }}) </a></td></tr>
<tr><td>5. Explain the features of each classification in Flynn's taxonomy. [Familiarity]</td><td>
     {{ range first 2 .Site.Taxonomies.cs2013details.arch_5 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/arch_5">See All ({{ len .Site.Taxonomies.cs2013details.arch_5 }}) </a>
</td></tr>
<tr><td>6. Describe assembly-level support for atomic operations. [Familiarity]</td>
  <td>   </td></tr>
<tr><td>7. Describe the challenges in maintaining cache coherence. [Familiarity]</td><td>
{{ range first 2 .Site.Taxonomies.cs2013details.arch_7 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/arch_7">See All ({{ len .Site.Taxonomies.cs2013details.arch_7 }}) </a>
</td></tr>
<tr><td>8. Describe the key performance challenges in different memory and distributed system topologies. [Familiarity]</td><td>
    {{ range first 2 .Site.Taxonomies.cs2013details.arch_8 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/arch_8">See All ({{ len .Site.Taxonomies.cs2013details.arch_8 }}) </a>
</td></tr>
</table>

<p><br></p>


<h3>Parallel Performance (<a href="{{ .Site.BaseURL }}/cs2013/pd_parallelperformance">{{ len .Site.Taxonomies.cs2013.pd_parallelperformance }} Activities  </a>
)</h3>

<table>
    <tr>
    <th width="60%">Learning Outcome</th> 
    <th>Unplugged Activities</th>
    <tr><th>Elective </th></tr>
<tr><td>1. Detect and correct a load imbalance. [Usage]</td><td>
{{ range first 2 .Site.Taxonomies.cs2013details.perf_1 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/perf_1">See All ({{ len .Site.Taxonomies.cs2013details.perf_1 }}) </a>
</td></tr>
<tr><td>2. Calculate the implications of Amdahl's law for a particular parallel algorithm (cross-reference SF/Evaluation for Amdahl's Law). [Usage]</td>
  <td>
    {{ range first 2 .Site.Taxonomies.cs2013details.perf_2 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/perf_2">See All ({{ len .Site.Taxonomies.cs2013details.perf_2 }}) </a></td></tr>
<tr><td>3. Describe how data distribution/layout can affect an algorithm's communication costs. [Familiarity]</td>
  <td>{{ range first 2 .Site.Taxonomies.cs2013details.perf_3 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/perf_3">See All ({{ len .Site.Taxonomies.cs2013details.perf_3 }}) </a></td></tr>
<tr><td>4. Detect and correct an instance of false sharing. [Usage]</td>
  <td>{{ range first 2 .Site.Taxonomies.cs2013details.perf_4 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/perf_4">See All ({{ len .Site.Taxonomies.cs2013details.perf_4 }}) </a>
  </td></tr>
<tr><td>5. Explain the impact of scheduling on parallel performance. [Familiarity]</td><td>
  {{ range first 2 .Site.Taxonomies.cs2013details.perf_5 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/perf_5">See All ({{ len .Site.Taxonomies.cs2013details.perf_5 }}) </a>
</td></tr>
<tr><td>6. Explain performance impacts of data locality. [Familiarity]</td><td>
{{ range first 2 .Site.Taxonomies.cs2013details.perf_6 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/perf_6">See All ({{ len .Site.Taxonomies.cs2013details.perf_6 }}) </a>
</td></tr>
<tr><td>7. Explain the impact and trade-off related to power usage on parallel performance. [Familiarity]</td><td>
</td></tr>
</table>

<p><br></p>

<h3>Distributed Systems (<a href="{{ .Site.BaseURL }}/cs2013/pd_distributedsystems">{{ len .Site.Taxonomies.cs2013.pd_distributedsystems }} Activities  </a>) </h3>
<table>
    <tr>
    <th width="60%">Learning Outcome</th> 
    <th>Unplugged Activities</th>
    <tr><th>Elective </th></tr>
<tr><td>1. Distinguish network faults from other kinds of failures. [Familiarity]</td><td></td></tr>
<tr><td>2. Explain why synchronization constructs such as simple locks are not useful in the presence of distributed faults. [Familiarity]</td><td></td></tr>
<tr><td>3. Write a program that performs any required marshaling and conversion into message units, such as packets, to communicate interesting data between two hosts. [Usage]</td><td></td></tr>
<tr><td>4. Measure the observed throughput and response latency across hosts in a given network. [Usage]</td><td></td></tr>
<tr><td>5. Explain why no distributed system can be simultaneously consistent, available, and partition tolerant. [Familiarity]</td><td></td></tr>
<tr><td>6. Implement a simple server -- for example, a spell checking service. [Usage]</td><td></td></tr>
<tr><td>7. Explain the tradeoffs among overhead, scalability, and fault tolerance when choosing a stateful v. stateless design for a given service. [Familiarity]</td><td></td></tr>
<tr><td>8. Describe the scalability challenges associated with a service growing to accommodate many clients, as well as those associated with a service only transiently having many clients. [Familiarity]</td><td></td></tr>
<tr><td>9. Give examples of problems for which consensus algorithms such as leader election are required. [Usage] </td><td>
  {{ range first 2 .Site.Taxonomies.cs2013details.ds_9 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/ds_9">See All ({{ len .Site.Taxonomies.cs2013details.ds_9 }}) </a>
</td></tr>
</table>

<p><br></p>


<h3>Cloud Computing (<a href="{{ .Site.BaseURL }}/cs2013/pd_cloudcomputing">{{ len .Site.Taxonomies.cs2013.pd_cloudcomputing }} Activities  </a>)</h3>

<table>
    <tr>
    <th width="60%">Learning Outcome</th> 
    <th>Unplugged Activities</th>
    <tr><th>Elective </th></tr>
<tr><td>1. Discuss the importance of elasticity and resource management in cloud computing. [Familiarity]</td><td></td></tr>
<tr><td>2. Explain strategies to synchronize a common view of shared data across a collection of devices.[Familiarity]</td><td>
   {{ range first 2 .Site.Taxonomies.cs2013details.cc_2 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/cc_2">See All ({{ len .Site.Taxonomies.cs2013details.cc_2 }}) </a>
</td></tr>
<tr><td>3. Explain the advantages and disadvantages of using virtualized infrastructure. [Familiarity]</td><td></td></tr>
<tr><td>4. Deploy an application that uses cloud infrastructure for computing and/or data resources. [Usage]</td><td></td></tr>
<tr><td>5. Appropriately partition an application between a client and resources. [Usage]</td><td></td></tr>
</table>

<p><br></p>

<h3>Formal Models and Semantics (<a href="{{ .Site.BaseURL }}/cs2013/pd_formalmodels">{{ len .Site.Taxonomies.cs2013.pd_formalmodels }} Activities  </a>)</h3>
<table>
    <tr>
    <th width="60%">Learning Outcome</th> 
    <th>Unplugged Activities</th>
    <tr><th>Elective </th></tr>
<tr><td>1. Model a concurrent process using a formal model, such as pi-calculus. [Usage]</td><td></td></tr>
<tr><td>2. Explain the characteristics of a particular formal parallel model. [Familiarity]</td><td></td></tr>
<tr><td>3. Formally model a shared memory system to show if it is consistent. [Usage]</td><td></td></tr>
<tr><td>4. Use a model to show progress guarantees in a parallel algorithm. [Usage]</td><td></td></tr>
<tr><td>5. Use formal techniques to show that a parallel algorithm is correct with respect to a safety or liveness property. [Usage]</td><td></td></tr>
<tr><td>6. Decide if a specific execution is linearizable or not. [Usage]</td><td>
   {{ range first 2 .Site.Taxonomies.cs2013details.formal_6 }}
    <a href="{{ .Permalink }}">{{ .LinkTitle }}</a>; 
    {{ end }}
    <a href="{{ $.Site.BaseURL }}/cs2013details/formal_6">See All ({{ len .Site.Taxonomies.cs2013details.formal_6 }}) </a>
</td></tr>
</table>

</main>

{{ partial "footer" . }}
